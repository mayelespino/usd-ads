{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Statistics Essentials and Data Pre-processing with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module outlines the techniques for effectively loading, processing and analyzing data in Python. In this process, we will also look at some of the preliminary statistics necessary to understand about the measures of centrality and variance of data. Datasets come from a wide range of sources and various formats, collections of documents, collections of images, collections of sound clips, collections of numerical measurements, or nearly anything else. Despite this apparent heterogeneity, it will help us to think of all data fundamentally as arrays of numbers.\n",
    "\n",
    "For example, text can be converted in various ways into numerical representations, perhaps binary digits representing the frequency of certain words or pairs of words. No matter what the data are, the first step in making it analyzable will be to transform them into arrays of numbers. For this reason, efficient storage and manipulation of numerical arrays is absolutely fundamental to the process of doing data science. In this module, we will go through the specialized tools that Python has for handling such numerical arrays: the NumPy package, and the Pandas package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will cover NumPy in detail. NumPy (short for Numerical Python) provides an efficient interface to store and operate on dense data buffers. In some ways, NumPy arrays are like Python's built-in list type, but NumPy arrays provide much more efficient storage and data operations as the arrays grow larger in size. NumPy arrays form the core of nearly the entire ecosystem of data science tools in Python, so time spent learning to use NumPy effectively will be valuable no matter what aspect of data science interests you.\n",
    "\n",
    "Topics Covered:\n",
    "\n",
    "- Understanding Array data type\n",
    "- Basics of Numpy Arrays\n",
    "- Computations on Numpy Arrays: Universal Functions\n",
    "- Aggregations: Min, Max, and Everything In Between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed the installation instructions for the course packages in your environment, you should have NumPy installed. Go ahead and try to import it. By convention, you'll find that most people in the scientific Python and Data Science communities will import NumPy using ``np`` as an alias. Throughout this course, you'll find that this is the way we will import and use NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__    # command to check the version of package installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder about Built In Documentation**\n",
    "\n",
    "As you work through this notebook, remember that Jupyter/IPython gives you the ability to quickly explore the contents of a package (by using the tab-completion feature), as well as the documentation of various functions (using the ``?`` character).\n",
    "\n",
    "For example, to display all the contents of the numpy namespace, you can type this:\n",
    "\n",
    "```ipython\n",
    "In [3]: np.<TAB>\n",
    "```\n",
    "\n",
    "And to display NumPy's built-in documentation, you can use this:\n",
    "\n",
    "```ipython\n",
    "In [4]: np?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Array Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the list data type in Python? It can be used to store a collection of data values, each of them belonging to a single data type or multiple data types. Storing and accessing a list comprised of multiple data types comes at a cost. Further, when working with datasets it is more often that we see a collection of data values of a single data type. \n",
    "\n",
    "Python offers several different options for storing data in efficient, fixed-type data buffers. The built-in ``array`` module is one such data type that can be used to create dense arrays of a uniform type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('i', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import array\n",
    "L = list(range(10))\n",
    "A = array.array('i', L)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here ``'i'`` is a type code indicating the contents are integers.\n",
    "\n",
    "Much more useful, however, is the ``ndarray`` object of the NumPy package.\n",
    "While Python's ``array`` object provides efficient storage of array-based data, NumPy adds to this efficient *operations* on that data.\n",
    "We will explore these operations in later sections; here we'll demonstrate several ways of creating a NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NumPy Arrays from Python Lists\n",
    "\n",
    "First, we can use ``np.array`` to create arrays from Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 5, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer array:\n",
    "np.array([1, 4, 2, 5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that unlike Python lists, NumPy is constrained to arrays that all contain the same type.\n",
    "If types do not match, NumPy will upcast if possible (here, integers are up-cast to floating point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.14, 4.  , 2.  , 3.  ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([3.14, 4, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to explicitly set the data type of the resulting array, we can use the ``dtype`` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3, 4], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, unlike Python lists, NumPy arrays can explicitly be multi-dimensional; here's one way of initializing a multidimensional array using a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [4, 5, 6],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nested lists result in multi-dimensional arrays\n",
    "np.array([range(i, i + 3) for i in [2, 4, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inner lists are treated as rows of the resulting two-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Arrays from Scratch\n",
    "\n",
    "Especially for larger arrays, it is more efficient to create arrays from scratch using routines built into NumPy.\n",
    "Here are several examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.14, 3.14, 3.14, 3.14, 3.14],\n",
       "       [3.14, 3.14, 3.14, 3.14, 3.14],\n",
       "       [3.14, 3.14, 3.14, 3.14, 3.14]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3x5 array filled with 3.14\n",
    "np.full((3, 5), 3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array filled with a linear sequence\n",
    "# Starting at 0, ending at 20, stepping by 2\n",
    "# (this is similar to the built-in range() function)\n",
    "np.arange(0, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71125897, 0.16526245, 0.43008959],\n",
       "       [0.61228252, 0.37038403, 0.06785738],\n",
       "       [0.48412739, 0.7476983 , 0.47720923]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3x3 array of uniformly distributed\n",
    "# random values between 0 and 1\n",
    "np.random.random((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 9, 3],\n",
       "       [9, 5, 6],\n",
       "       [5, 1, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3x3 array of random integers in the interval [0, 10)\n",
    "np.random.randint(0, 10, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics of NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data manipulation in Python is nearly synonymous with NumPy array manipulation: even newer tools like Pandas are built around the NumPy array.\n",
    "This section will present several examples of using NumPy array manipulation to access data and subarrays, and to split, reshape, and join the arrays. Get to know them well!\n",
    "\n",
    "We'll cover a few categories of basic array manipulations here:\n",
    "\n",
    "- *Attributes of arrays*: Determining the size, shape, memory consumption, and data types of arrays\n",
    "- *Indexing of arrays*: Getting and setting the value of individual array elements\n",
    "- *Slicing of arrays*: Getting and setting smaller subarrays within a larger array\n",
    "- *Reshaping of arrays*: Changing the shape of a given array\n",
    "- *Joining and splitting of arrays*: Combining multiple arrays into one, and splitting one array into many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Array Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's discuss some useful array attributes.\n",
    "We'll start by defining three random arrays, a one-dimensional, two-dimensional, and three-dimensional array.\n",
    "We'll use NumPy's random number generator, which we will *seed* with a set value in order to ensure that the same random arrays are generated each time this code is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # One-dimensional array\n",
    "x2 = np.random.randint(10, size=(3, 4))  # Two-dimensional array\n",
    "x3 = np.random.randint(10, size=(3, 4, 5))  # Three-dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each array has attributes ``ndim`` (the number of dimensions), ``shape`` (the size of each dimension), and ``size`` (the total size of the array). Another useful attribute is the ``dtype``, the data type of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x3 ndim:  3\n",
      "x3 shape: (3, 4, 5)\n",
      "x3 size:  60\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"x3 ndim: \", x3.ndim)\n",
    "print(\"x3 shape:\", x3.shape)\n",
    "print(\"x3 size: \", x3.size)\n",
    "print(\"dtype:\", x3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Indexing: Accessing Single Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are familiar with Python's standard list indexing, indexing in NumPy will feel quite familiar.\n",
    "In a one-dimensional array, the $i^{th}$ value (counting from zero) can be accessed by specifying the desired index in square brackets, just as with Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 3, 3, 7, 9])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[1]  # indexing starts with 0 in Python, so index 1 is the second element in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[-1]  # use negative indices to index from the end of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a multi-dimensional array, items can be accessed using a comma-separated tuple of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 5, 2, 4],\n",
       "       [7, 6, 8, 8],\n",
       "       [1, 6, 7, 7]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[2, 0]  # first value indicates row index and second value indicates column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[2, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values can also be modified using any of the above index notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2,  4],\n",
       "       [ 7,  6,  8,  8],\n",
       "       [ 1,  6,  7,  7]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[0, 0] = 12\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that, unlike Python lists, NumPy arrays have a fixed type.\n",
    "This means, for example, that if you attempt to insert a floating-point value to an integer array, the value will be silently truncated. Try it out for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Slicing: Accessing Subarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we can use square brackets to access individual array elements, we can also use them to access subarrays with the *slice* notation, marked by the colon (``:``) character.\n",
    "The NumPy slicing syntax follows that of the standard Python list; to access a slice of an array ``x``, use this:\n",
    "``` python\n",
    "x[start:stop:step]\n",
    "```\n",
    "If any of these are unspecified, they default to the values ``start=0``, ``stop=``*``size of dimension``*, ``step=1``.\n",
    "We'll take a look at accessing sub-arrays in one dimension and in multiple dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-dimensional subarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[5:]  # elements after index 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4:7]  # middle sub-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[::2]  # every other element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potentially confusing case is when the ``step`` value is negative.\n",
    "In this case, the defaults for ``start`` and ``stop`` are swapped.\n",
    "This becomes a convenient way to reverse an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[5::-2]  # reversed every other from index 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-dimensional subarrays\n",
    "\n",
    "Multi-dimensional slices work in the same way, with multiple slices separated by commas.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2,  4],\n",
       "       [ 7,  6,  8,  8],\n",
       "       [ 1,  6,  7,  7]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  5,  2],\n",
       "       [ 7,  6,  8]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[:2, :3]  # two rows, three columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One commonly needed routine is accessing of single rows or columns of an array.\n",
    "This can be done by combining indexing and slicing, using an empty slice marked by a single colon (``:``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(x2[:, 1])  # second column of x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating copies of arrays\n",
    "\n",
    "It is sometimes useful to explicitly copy the data within an array or a subarray. This can be most easily done with the ``copy()`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  5]\n",
      " [ 7  6]]\n"
     ]
    }
   ],
   "source": [
    "x2_sub_copy = x2[:2, :2].copy()\n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now modify this subarray, the original array is not touched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  5]\n",
      " [ 7  6]]\n"
     ]
    }
   ],
   "source": [
    "x2_sub_copy[0, 0] = 42\n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping of Arrays\n",
    "\n",
    "Another useful type of operation is reshaping of arrays.\n",
    "The most flexible way of doing this is with the ``reshape`` method.\n",
    "For example, if you want to put the numbers 1 through 9 in a $3 \\times 3$ grid, you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "grid = np.arange(1, 10).reshape((3, 3))\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for this to work, the size of the initial array must match the size of the reshaped array. \n",
    "Where possible, the ``reshape`` method will use a no-copy view of the initial array, but with non-contiguous memory buffers this is not always the case.\n",
    "\n",
    "Another common reshaping pattern is the conversion of a one-dimensional array into a two-dimensional row or column matrix.\n",
    "This can be done with the ``reshape`` method, or more easily done by making use of the ``newaxis`` keyword within a slice operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "\n",
    "# column vector via reshape\n",
    "x.reshape((3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Concatenation and Splitting\n",
    "\n",
    "All of the preceding routines worked on single arrays. It's also possible to combine multiple arrays into one, and to conversely split a single array into multiple arrays. We'll take a look at those operations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation of arrays\n",
    "\n",
    "Concatenation, or joining of two arrays in NumPy, is primarily accomplished using the routines ``np.concatenate``, ``np.vstack``, and ``np.hstack``.\n",
    "``np.concatenate`` takes a tuple or list of arrays as its first argument, as we can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 3, 2, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([3, 2, 1])\n",
    "np.concatenate([x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be used for two-dimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 2, 3],\n",
       "       [4, 5, 6, 4, 5, 6]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate along the second axis (zero-indexed)\n",
    "np.concatenate([grid, grid], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting of arrays\n",
    "\n",
    "The opposite of concatenation is splitting, which is implemented by the functions ``np.split``, ``np.hsplit``, and ``np.vsplit``.  For each of these, we can pass a list of indices giving the split points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [99 99] [3 2 1]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3, 99, 99, 3, 2, 1]\n",
    "x1, x2, x3 = np.split(x, [3, 5])\n",
    "print(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation on NumPy Arrays: Universal Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we have been discussing some of the basic nuts and bolts of NumPy; in the next few sections, we will dive into the reasons that NumPy is so important in the Python data science world.\n",
    "Namely, it provides an easy and flexible interface to optimized computation with arrays of data.\n",
    "\n",
    "Computation on NumPy arrays can be very fast, or it can be very slow.\n",
    "The key to making it fast is to use *vectorized* operations, generally implemented through NumPy's *universal functions* (ufuncs).\n",
    "This section motivates the need for NumPy's ufuncs, which can be used to make repeated calculations on array elements much more efficient.\n",
    "It then introduces many of the most common and useful arithmetic ufuncs available in the NumPy package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Slowness of Loops\n",
    "\n",
    "Python's default implementation (known as CPython) does some operations very slowly.\n",
    "This is in part due to the dynamic, interpreted nature of the language: the fact that types are flexible, so that sequences of operations cannot be compiled down to efficient machine code as in languages like C and Fortran.\n",
    "Recently there have been various attempts to address this weakness: well-known examples are the [PyPy](http://pypy.org/) project, a just-in-time compiled implementation of Python; the [Cython](http://cython.org) project, which converts Python code to compilable C code; and the [Numba](http://numba.pydata.org/) project, which converts snippets of Python code to fast LLVM bytecode.\n",
    "Each of these has its strengths and weaknesses, but it is safe to say that none of the three approaches has yet surpassed the reach and popularity of the standard CPython engine.\n",
    "\n",
    "The relative sluggishness of Python generally manifests itself in situations where many small operations are being repeated – for instance looping over arrays to operate on each element.\n",
    "For example, imagine we have an array of values and we'd like to compute the reciprocal of each.\n",
    "A straightforward approach might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 1.        , 0.25      , 0.25      , 0.125     ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)  # seed for reproducability\n",
    "\n",
    "def compute_reciprocals(values):\n",
    "    output = np.empty(len(values))  # create an empty array of same length as input array \n",
    "    for i in range(len(values)):\n",
    "        output[i] = 1.0 / values[i]  # perform reciprocal operation within for loop\n",
    "    return output\n",
    "        \n",
    "values = np.random.randint(1, 10, size=5)  # 1D array of length 5 with values between 1 to 10\n",
    "compute_reciprocals(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation probably feels fairly natural to someone from, say, a C or Java background.\n",
    "But if we measure the execution time of this code for a large input, we see that this operation is very slow, perhaps surprisingly so!\n",
    "We'll benchmark this with IPython's ``%timeit``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.98 s ± 265 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "big_array = np.random.randint(1, 100, size=1000000)\n",
    "%timeit compute_reciprocals(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes several seconds to compute these million operations and to store the result!\n",
    "When even cell phones have processing speeds measured in Giga-FLOPS (i.e., billions of numerical operations per second), this seems almost absurdly slow.\n",
    "It turns out that the bottleneck here is not the operations themselves, but the type-checking and function dispatches that CPython must do at each cycle of the loop.\n",
    "Each time the reciprocal is computed, Python first examines the object's type and does a dynamic lookup of the correct function to use for that type.\n",
    "If we were working in compiled code instead, this type specification would be known before the code executes and the result could be computed much more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing UFuncs\n",
    "\n",
    "For many types of operations, NumPy provides a convenient interface into just this kind of statically typed, compiled routine. This is known as a *vectorized* operation.\n",
    "This can be accomplished by simply performing an operation on the array, which will then be applied to each element.\n",
    "This vectorized approach is designed to push the loop into the compiled layer that underlies NumPy, leading to much faster execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the execution time for our big array, we see that it completes orders of magnitude faster than the Python loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.92 ms ± 246 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (1.0 / big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized operations in NumPy are implemented via *ufuncs*, whose main purpose is to quickly execute repeated operations on values in NumPy arrays.\n",
    "Ufuncs are extremely flexible – operations are not limited to one-dimensional arrays–they can also act on multi-dimensional arrays as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   4],\n",
       "       [  8,  16,  32],\n",
       "       [ 64, 128, 256]], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9).reshape((3, 3))\n",
    "2 ** x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computations using vectorization through ufuncs are nearly always more efficient than their counterpart implemented using Python loops, especially as the arrays grow in size.\n",
    "Any time you see such a loop in a Python script, you should consider whether it can be replaced with a vectorized expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring NumPy's UFuncs\n",
    "\n",
    "Ufuncs exist in two flavors: *unary ufuncs*, which operate on a single input, and *binary ufuncs*, which operate on two inputs.\n",
    "We'll see examples of both these types of functions here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array arithmetic\n",
    "\n",
    "NumPy's ufuncs feel very natural to use because they make use of Python's native arithmetic operators.\n",
    "The standard addition, subtraction, multiplication, and division can all be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x     = [0 1 2 3]\n",
      "x + 5 = [5 6 7 8]\n",
      "x - 5 = [-5 -4 -3 -2]\n",
      "x * 2 = [0 2 4 6]\n",
      "x / 2 = [0.  0.5 1.  1.5]\n",
      "x // 2 = [0 0 1 1]\n",
      "-x     =  [ 0 -1 -2 -3]\n",
      "x ** 2 =  [0 1 4 9]\n",
      "x % 2  =  [0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(4)\n",
    "print(\"x     =\", x)\n",
    "print(\"x + 5 =\", x + 5)\n",
    "print(\"x - 5 =\", x - 5)\n",
    "print(\"x * 2 =\", x * 2)\n",
    "print(\"x / 2 =\", x / 2)\n",
    "print(\"x // 2 =\", x // 2)  # floor division\n",
    "print(\"-x     = \", -x)\n",
    "print(\"x ** 2 = \", x ** 2)\n",
    "print(\"x % 2  = \", x % 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, these can be strung together however you wish, and the standard order of operations is respected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.  , -2.25, -4.  , -6.25])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(0.5*x + 1) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ufunc Features\n",
    "\n",
    "Many NumPy users make use of ufuncs without ever learning their full set of features.\n",
    "We'll outline a few specialized features of ufuncs here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying output\n",
    "\n",
    "For large calculations, it is sometimes useful to be able to specify the array where the result of the calculation will be stored.\n",
    "Rather than creating a temporary array, this can be used to write computation results directly to the memory location where you'd like them to be.\n",
    "For all ufuncs, this can be done using the ``out`` argument of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 10. 20. 30. 40.]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(5)\n",
    "y = np.empty(5)\n",
    "np.multiply(x, 10, out=y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregates\n",
    "\n",
    "For binary ufuncs, there are some interesting aggregates that can be computed directly from the object.\n",
    "For example, if we'd like to *reduce* an array with a particular operation, we can use the ``reduce`` method of any ufunc.\n",
    "A reduce repeatedly applies a given operation to the elements of an array until only a single result remains.\n",
    "\n",
    "For example, calling ``reduce`` on the ``add`` ufunc returns the sum of all elements in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(1, 6)\n",
    "np.add.reduce(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on universal functions (including the full list of available functions) can be found on the [NumPy](http://www.numpy.org) documentation website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations: Min, Max, and Everything In Between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when faced with a large amount of data, a first step is to compute summary statistics for the data in question.\n",
    "Perhaps the most common summary statistics are the mean and standard deviation, which allow you to summarize the \"typical\" values in a dataset, but other aggregates are useful as well (the sum, product, median, minimum and maximum, quantiles, etc.).\n",
    "\n",
    "NumPy has fast built-in aggregation functions for working on arrays; we'll discuss and demonstrate some of them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing the Values in an Array\n",
    "\n",
    "Consider computing the sum of all values in an array.\n",
    "Python itself can do this using the built-in ``sum`` function. However, NumPy's version ``np.sum`` of the operation is computed much more quickly because it executes the operation in compiled code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215 ms ± 17.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.01 ms ± 131 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "big_array = np.random.rand(1000000)\n",
    "%timeit sum(big_array)\n",
    "%timeit np.sum(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, though: the ``sum`` function and the ``np.sum`` function are not identical, which can sometimes lead to confusion!\n",
    "In particular, their optional arguments have different meanings, and ``np.sum`` is aware of multiple array dimensions, as we will see in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum and Maximum\n",
    "\n",
    "Similarly, Python has built-in ``min`` and ``max`` functions, used to find the minimum value and maximum value of any given array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.071203171893359e-07, 0.9999997207656334)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(big_array), max(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy's corresponding functions have similar syntax, and again operate much more quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.071203171893359e-07, 0.9999997207656334)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(big_array), np.max(big_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 ms ± 7.52 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "479 µs ± 68.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit min(big_array)\n",
    "%timeit np.min(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi dimensional aggregates\n",
    "\n",
    "One common type of aggregation operation is an aggregate along a row or column.\n",
    "Say you have some data stored in a two-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71125897 0.16526245 0.43008959 0.61228252]\n",
      " [0.37038403 0.06785738 0.48412739 0.7476983 ]\n",
      " [0.47720923 0.23956676 0.87236336 0.36038331]]\n"
     ]
    }
   ],
   "source": [
    "M = np.random.random((3, 4))\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation functions take an additional argument specifying the *axis* along which the aggregate is computed. For example, we can find the minimum value within each column by specifying ``axis=0``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37038403, 0.06785738, 0.43008959, 0.36038331])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.min(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns four values, corresponding to the four columns of numbers. Similarly, we can find the maximum value within each row. The way the axis is specified here can be confusing to users coming from other languages.\n",
    "The ``axis`` keyword specifies the *dimension of the array that will be collapsed*, rather than the dimension that will be returned.\n",
    "So specifying ``axis=0`` means that the first axis will be collapsed: for two-dimensional arrays, this means that values within each column will be aggregated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other aggregation functions\n",
    "\n",
    "NumPy provides many other aggregation functions, but we won't discuss them in detail here.\n",
    "Additionally, most aggregates have a ``NaN``-safe counterpart that computes the result while ignoring missing/null values, which are marked by the special IEEE floating-point ``NaN`` value.\n",
    "Some of these ``NaN``-safe functions were not added until NumPy 1.8, so they will not be available in older NumPy versions.\n",
    "\n",
    "The following table provides a list of useful aggregation functions available in NumPy:\n",
    "\n",
    "|Function Name      |   NaN-safe Version  | Description                                   |\n",
    "|-------------------|---------------------|-----------------------------------------------|\n",
    "| ``np.sum``        | ``np.nansum``       | Compute sum of elements                       |\n",
    "| ``np.prod``       | ``np.nanprod``      | Compute product of elements                   |\n",
    "| ``np.mean``       | ``np.nanmean``      | Compute mean of elements                      |\n",
    "| ``np.std``        | ``np.nanstd``       | Compute standard deviation                    |\n",
    "| ``np.var``        | ``np.nanvar``       | Compute variance                              |\n",
    "| ``np.min``        | ``np.nanmin``       | Find minimum value                            |\n",
    "| ``np.max``        | ``np.nanmax``       | Find maximum value                            |\n",
    "| ``np.argmin``     | ``np.nanargmin``    | Find index of minimum value                   |\n",
    "| ``np.argmax``     | ``np.nanargmax``    | Find index of maximum value                   |\n",
    "| ``np.median``     | ``np.nanmedian``    | Compute median of elements                    |\n",
    "| ``np.percentile`` | ``np.nanpercentile``| Compute rank-based statistics of elements     |\n",
    "| ``np.any``        | N/A                 | Evaluate whether any elements are true        |\n",
    "| ``np.all``        | N/A                 | Evaluate whether all elements are true        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On to Pandas\n",
    "There is defintely more to NumPy, it provides several other useful features like array broadcasting, boolean masking, advanced indexing and sorting to name a few. But this is a good time to stop and practice all the core concepts discussed here. As you get more comfortable with these basic building blocks, it will be easier to learn the rest of the features offered by Numpy. Let us now move on to Pandas in the next notebook, which builds on the data structures that we learned in Numpy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas.* *The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
